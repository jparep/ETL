# dbt_project.yml - Configuration for the employee ETL pipeline
name: 'dbt_project'  # Project name, lowercase with underscores, reflects ETL purpose
version: '1.0.0'      # Version for tracking changes
config-version: 2     # dbt configuration version

profile: 'snowflake'   # Profile name for Snowflake connection, defined in profiles.yml

# Directory paths for dbt files
model-paths: ["models"]           # Where models (SQL files) are stored
analysis-paths: ["analyses"]      # For analytical queries (optional)
test-paths: ["tests"]            # For dbt tests
seed-paths: ["seeds"]            # For seed data (optional)
macro-paths: ["macros"]          # For dbt macros (e.g., custom functions)

# Output and cleanup settings
target-path: "target"            # Directory for compiled files and logs
clean-targets:                   # Files/directories to clean up
  - "target"                    # Compiled output
  - "dbt_packages"             # External dbt packages

# Model configurations, specifying materialization and structure
models:
  dbt_project:                  # Namespace matches project name
    staging:                    # Staging models for validation
      materialized: view        # Materialize as views for non-persistent validation
    raw:                        # Raw models for target table creation
      materialized: table       # Materialize as tables for persistence
    transformed:                # Transformed models for analytics
      materialized: table       # Materialize as tables for persistence

# Hook to run ETL validation after each dbt run
on-run-end:
  - "{{ validate_etl_data('employee_db.employee.employees') }}"  # Custom macro for data validation